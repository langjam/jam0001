# inference engine

The inference engine is a `BERT` model deployed on hugging face.

Data was acquired from random internet lists & reddit.

[Training code](TODO) was modified from [here](https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/text_classification.ipynb) (colabs).

`$repo/server` handles the inference. 
If you know how to use a hugging face model in-browser (like with tensorflow js), please open an issue to tell me.